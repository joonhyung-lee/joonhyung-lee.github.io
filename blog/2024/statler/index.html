<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <blockquote> <p>Arxiv. [<a href="https://arxiv.org/pdf/2306.17840.pdf" rel="external nofollow noopener" target="_blank">Paper</a>] [<a href="https://statler-lm.github.io/" rel="external nofollow noopener" target="_blank">Project Page</a>]</p> <p>Takuma Yoneda<sup>*1</sup>, Jiading Fang<sup>*1</sup>, Peng Li<sup>*2</sup>, Huanyu Zhang<sup>*3</sup>, Tianchong Jiang<sup>3</sup>, Shengjie Lin<sup>1</sup>, Ben Picker<sup>3</sup>, David Yunis<sup>1</sup> Hongyuan Mei<sup>1</sup>, Matthew R. Walter<sup>1</sup> <sup>1</sup>TTI-Chicago, <sup>2</sup>Fudan University, <sup>3</sup>University of Chicago, *Equal Contribution</p> <p>Dec. 4</p> </blockquote> <div align="center"> <img src="/assets/img/statler/statler_teaser.png" width="100%"> <p>Fig. 1: Overview of Statler.</p> </div> <h3 id="한-문장-요약">한 문장 요약</h3> <ul> <li>World State를 갱신해가며 LLM Reasoning을 수행하자.</li> </ul> <h3 id="contribution">Contribution</h3> <ul> <li>기존 LLM 방식은 자신이 뱉어준 Action과 Observation에 기인해 reasoning을 수행해왔음. <ul> <li>Traditional LLMs in robotics generate actions based only on prior actions and observations, lacking <strong>an explicit</strong> world state.</li> </ul> </li> <li>2개의 prompted LLM을 통해 world-state를 <strong>explicit</strong>하게 maintaining 하겠다는 의도. <blockquote> <p>Statler utilizes a pair of prompted LLMs: instructed by a few demonstrations, <strong>the world-state reader</strong> takes as input the user query, reads the estimated world state, and generates an executable action (e.g, a code snippet); instructed by another set of demonstrations, <strong>the world-state writer</strong> updates the world state estimate based on the action.</p> </blockquote> </li> <li>이를 통해 Long-Horizon LLM Interaction에서 기억을 소실하거나, misleading reasoning을 방지해준다고 함.</li> </ul> <h3 id="motivation">Motivation</h3> <div align="center"> <img src="/assets/img/statler/statler-motivation.png" width="100%"> <p>Fig. 2: Motivation of Statler.</p> </div> <ul> <li>야바위 게임처럼, 컵 안의 물체는 계속해서 움직이게 되는데, 우리가 명시적으로 공의 움직임을 관찰하지는 못하지만, internal-representation에 의해 공이 어떠한 컵에 들어있는지 알 수 있다.</li> <li>이것에서 영감을 얻어, LLM이 관측하지 못하는 world-state에 대해 maintaining하는 방향으로 연구를 수행함.</li> </ul> <h3 id="methodology">Methodology</h3> <div align="center"> <div style="display: flex; justify-content: center; align-items: center;"> <div style="flex: 50%;"> <img src="/assets/img/statler/statler-world-reader.png" style="width: 100%;"> <p>Fig. 3: World State Reader.</p> </div> <div style="flex: 50%;"> <img src="/assets/img/statler/statler-world-writer.png" style="width: 100%;"> <p>Fig. 4: World State Writer.</p> </div> </div> </div> <ul> <li>World-State-Reader <ul> <li>reader는 현재 state를 고려한 action을 취해주는 LLM 역할.</li> <li>여기서 state가 update 되어야 하는 부분도 고려해서 답변을 만듦.</li> </ul> </li> <li>World-State-Writer <ul> <li>앞선 reader가 추론해낸 state에 기반해, state를 upadte하고, external memory에 저장함. (이것이 곧 current-state가 됨.)</li> </ul> </li> </ul> <h3 id="experiments">Experiments</h3> <div align="center"> <img src="/assets/img/statler/statler-example.png" width="50%"> <p>Fig. 5: Example scenario about Statler.</p> </div> <h3 id="thoughts">Thoughts:</h3> <ul> <li>저자가 언급한 야바위 문제로 motivation을 얘기하느데, 이 점이 꽤나 재밌게 느껴졌습니다.</li> <li>지금 GPT-4V로 연구를 수행하며 느낀 점이, long-horizon interaction을 수행할 때에 기억을 소실한다는 것이었습니다.</li> <li>저자는 GPT-4 모델로 <strong>state-reader, state-writer</strong> 두 개로 역할을 나누어 이러한 기억 소실을 방지해내고자 했습니다. <ul> <li>appendix도 읽어보았으나, prompt에 대해 novel한 부분을 찾지는 못했습니다. world-state를 template에 맞게 뱉어주고, 이에 기반해 world-state를 업데이트 시켰다고 하는데, 단순히 이것 만으로 기억 소실을 개선시켰다는 점이 신기합니다.</li> </ul> </li> </ul> </body></html>